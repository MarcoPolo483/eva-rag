{
  "$schema": "https://marcopolo483.github.io/eva-suite/schemas/eva-memory-v1.json",
  "version": "1.0.0",
  "repo": {
    "name": "eva-rag",
    "pod": "POD-F",
    "purpose": "Retrieval-Augmented Generation engine for EVA Suite. Document ingestion (PDF/DOCX/TXT), text chunking (500 tokens, 50 overlap), vector embedding (Azure OpenAI text-embedding-3-small), hybrid search (vector + BM25), reranking (cross-encoder), citation extraction. Reference implementation: OpenWebUI retrieval patterns + PubSec Info Assistant Azure AI Search.",
    "status": "active",
    "owner": "P04-LIB + P06-RAG",
    "dependencies": [
      "eva-orchestrator (specification in docs/SPECIFICATION.md)",
      "eva-core (Document entity, Query entity)",
      "Azure AI Search (vector index, hybrid search)",
      "Azure OpenAI (text-embedding-3-small)",
      "Azure Blob Storage (document files)",
      "Redis (embedding cache)",
      "FastAPI (API framework)",
      "LangChain (text splitting, retrieval)",
      "Sentence Transformers (reranking)"
    ],
    "lastUpdated": "2025-12-08T23:45:00Z"
  },
  "context": {
    "summary": "Azure AI Search Integration COMPLETE (2025-12-09T11:43:00+00:00 | December 9, 2025 at 6:43 AM EST): ✅ Critical blocker resolved - vector search indexing operational. Index 'eva-rag-chunks' created with HNSW algorithm (m=4, ef_construction=400). Hybrid search (vector + BM25) working with 433ms avg latency (target: <500ms). Azure OpenAI text-embedding-3-small deployed in ao-sandbox. Phase 1 complete + Phase 2 indexing operational. Next: Re-index 2,167 existing documents, implement cross-encoder reranking, address P0 issues (table-aware chunking, synthetic data flags). Phase 2 jurisprudence spec still awaiting approval (800 cases, $0.51 cost).",
    "keyFiles": [
      "docs/AZURE-AI-SEARCH-IMPLEMENTATION.md (Complete implementation docs - NEW)",
      "docs/RAG-CAPABILITIES-VS-DATA-PIPELINE.md (Gap analysis - 545 lines)",
      "TEST-RESULTS-AZURE-SEARCH.md (Test results Dec 9, 2025 - NEW)",
      "test_search_integration.py (Comprehensive test suite - 273 lines - NEW)",
      "src/eva_rag/services/search_service.py (Azure AI Search integration - 427 lines - NEW)",
      "src/eva_rag/api/search.py (POST /api/v1/rag/search endpoint - 146 lines - NEW)",
      "src/eva_rag/models/search.py (SearchRequest/Response models - NEW)",
      "docs/SPECIFICATION.md (Complete specification - 834 lines)",
      "src/eva_rag/services/ingestion_service.py (TODO line 157 COMPLETED - auto-indexing)",
      "ingest_legal_documents.py (Multi-client legal ingestion - READY FOR RE-INDEX)"
    ],
    "currentPhase": "Phase 2 INDEXING OPERATIONAL ✅ | Next: Re-index 2,167 docs → Test queries → Implement reranking → Phase 2 jurisprudence approval",
    "openIssues": 3,
    "blockers": []
  },
  "quality": {
    "testCoverage": 95,
    "lintWarnings": 0,
    "typeScriptStrict": false,
    "wcagCompliance": "N/A",
    "bilingualStatus": "EN-CA/FR-CA (language detection implemented, chunking/search pending Phase 2-3)"
  },
  "memory": {
    "lessons": [
      "✅ Azure AI Search Integration (Dec 9, 2025): HNSW algorithm (m=4, ef_construction=400) achieves 433ms avg search latency - within 500ms target",
      "✅ Hybrid search (vector + BM25 with RRF fusion k=60) operational - combines semantic and keyword matching",
      "✅ Azure OpenAI text-embedding-3-small deployment in ao-sandbox resource working (1536 dims)",
      "⚠️ First query takes ~1000ms (includes embedding generation), subsequent queries ~150-200ms",
      "✅ Empty index handling: Graceful degradation with 0 results, no errors",
      "✅ Ingestion pipeline auto-indexes chunks in Azure AI Search after embedding generation (TODO line 157 completed)",
      "Phase 2: Jurisprudence requires text-embedding-3-large (3072 dims) not text-embedding-3-small (1536 dims) for legal precision",
      "Phase 2: Hybrid semantic + structural chunking preserves legal reasoning flow (Facts → Issue → Analysis → Ruling)",
      "Phase 2: 4 tribunals discovered (SCC, FC, FCA, SST) each need 100 sample cases in EN + FR = 800 total cases",
      "Phase 2: Complete jurispipeline package exists in eva-orchestrator with 4-stage pipeline (Discover → Fetch → Normalize → Publish)",
      "Phase 2: Date format rule - ALWAYS use 2025 not 2024 (EVA Suite built Nov 2-Dec 8, 2025 = 36 days)",
      "Phase 1: Document loaders with PyPDF2/python-docx work well, preserve page numbers for citations",
      "Phase 1: Language detection with langdetect is fast and accurate for EN/FR (default to EN for edge cases)",
      "Phase 1: Tenant isolation via {tenant_id}/{space_id}/{document_id} path prevents data leaks",
      "Phase 1: Dual datetime format (ISO 8601 + human-readable) improves UX in logs and responses",
      "Phase 1: Comprehensive tests (37 tests) with mocked Azure services enable rapid development without live deps",
      "Use LangChain RecursiveCharacterTextSplitter for semantic chunking (500 tokens, 50 overlap)",
      "Batch embed 100 chunks per Azure OpenAI API call (reduce latency from 10s to 2s)",
      "Cache embeddings in Redis by content hash (60%+ cache hit rate, reduce costs)",
      "Hybrid search (vector + BM25) with RRF fusion outperforms pure vector search",
      "Rerank top-20 results with cross-encoder (filter < 0.5 relevance score)"
      ,
      "✅ Structural compliance (Dec 30, 2025): Added .eva-manifest.json + LICENSE; validator PASS (32/32 folders, 5/5 files); stashed untracked ingestion samples with longpaths enabled; repo status clean for push."
    ],
    "tools": [
      "FastAPI (async API endpoints, OpenAPI auto-docs)",
      "LangChain (text splitting, retrieval patterns)",
      "Azure AI Search (vector index, hybrid search, semantic reranker)",
      "Azure OpenAI (text-embedding-3-small, 1536 dims)",
      "Sentence Transformers (ms-marco-MiniLM-L-6-v2 cross-encoder)",
      "PyPDF2 + python-docx (document loaders)",
      "Redis (embedding cache)",
      "pytest + coverage.py (testing, 95% coverage)"
    ],
    "patterns": [
      "✅ Phase 2 Indexing Complete: Upload → Extract → Detect Language → Chunk → Embed → Index (Azure AI Search) → Store (status=INDEXED)",
      "Phase 1 Complete: Upload → Extract (PyPDF2/python-docx) → Detect Language (langdetect) → Store (Azure Blob + Cosmos DB)",
      "Document Ingestion: Upload → Extract → Detect Language → Chunk → Embed → Index",
      "Chunking: RecursiveCharacterTextSplitter (500 tokens, 50 overlap, sentence boundaries)",
      "Embedding: Batch 100 chunks, cache by hash (Redis 7-day TTL)",
      "Hybrid Search: Vector (cosine similarity) + Keyword (BM25) → RRF fusion (k=60)",
      "Search Flow: Query → Generate Embedding (100ms) → Hybrid Search (150-250ms) → Return Results (< 500ms total)",
      "Reranking: Cross-encoder top-20 → filter < 0.5 → return top-K",
      "Citation: Extract document_name, page_number, content snippet for each result",
      "Tenant Isolation: Filter all operations by space_id + tenant_id"
    ]
  },
  "reports": {
    "lastHousekeeping": null,
    "lastAudit": null,
    "lastTestRun": null,
    "cachePath": ".eva-cache/"
  },
  "bootstrap": {
    "readOnOpen": true,
    "autoUpdate": "nightly",
    "backupEnabled": true,
    "backupPath": ".eva-cache/backups/"
  },
  "_metadata": {
    "createdBy": "EVA-Orchestrator Specification Generation (eva-rag RAG engine)",
    "createdAt": "2025-12-07T00:00:00Z",
    "templateVersion": "1.0.0",
    "lastModifiedBy": "GitHub Copilot (Azure AI Search Integration Complete)",
    "lastModifiedAt": "2025-12-09T11:43:00+00:00",
    "lastModifiedAtDisplay": "December 9, 2025 at 6:43 AM EST"
  }
}
